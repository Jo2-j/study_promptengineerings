{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 기본 불러오는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/apps/study_promptengineerings/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        별 한 게토 았깝땀. 왜 싸람듯릭 펼 1캐를 쥰눈징 컥꺾폰 싸람믐롯섞 맒록 섧멍핥쟈...\n",
       "1                                   잚많 쟉꼬 갉 태 좋눼욥. 차못동 줆 ㅋ\n",
       "2                                          절테 간면 않 된는 굣 멥몫\n",
       "3        야... 칵컥 좋꾜 부됴 뼝 뚫렷썹 신원햐쥠만 닮패 넴센 밌쪄벅림. 샥퀘 핥류만 묵...\n",
       "4        집윈 축쳐눌료 딴너왓눈뎁 카셩뷔 좋곱 칼쿰한네올. 쩌럼한뒈 뮬콰 욺료토 잊쿄 빻토 ...\n",
       "                               ...                        \n",
       "11258    셩슉키 텍많 퓌함먼 될 겯 갔따오. 첵쿠인돈 쪼쉭됴 출 한짬 셩셔오... 냠멎쥔는 ...\n",
       "11259    핫운뜬 홋뗄뤼 낄쩍젓구롯 댜씨 횃쌩햐눈 펍붊 앍렬춘닷. 구태 읗뎃했떤 홀뗄 짙건둘운...\n",
       "11260           효텔 중 썹삣수값 쬐곤댜만 싸람익 념뭍 많야셔 뭘 핥둔 쉬깎닌 많힙 걸륀댜.\n",
       "11261    윈떼뤼연왕 칵걱쿤 낮뿌찌 않앝뎐 껏 갇툰뒈, 졺 옹레퇸 눅킴뮈 읽서셔 굵런찌 삵짝 ...\n",
       "11262    퓸 긁뤽교 륨셥삣수까 깍껴귐 처럼한 컷쒜 피헤 맏읾쓺. 룸셔뷜슭 움씨굻 멱코 싶뻤서...\n",
       "Name: input, Length: 11263, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encrypted_data = train['input']\n",
    "input_encrypted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 길이 다른거 출력하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 사용할 토크나이저 로드 (예: BERT 토크나이저)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 입력 데이터 (예제 데이터)\n",
    "input_encrypted_data = train['input']\n",
    "\n",
    "# 토큰화 수행\n",
    "output_from_tokenizer = tokenizer.encode(input_encrypted_data, add_special_tokens=True)\n",
    "\n",
    "# 길이 비교\n",
    "tokenized_words_length = len(output_from_tokenizer)\n",
    "original_words_length = len(train['output'])\n",
    "\n",
    "difference = original_words_length - tokenized_words_length\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Original Encrypted Data:\", input_encrypted_data)\n",
    "print(\"Tokenized Output:\", tokenized_words_length)\n",
    "print(\"Original Length:\", original_words_length)\n",
    "print(\"Tokenized Length:\", tokenized_words_length)\n",
    "print(\"Length Difference:\", difference)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
