{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set missing values:\n",
      "매물확인방식      0\n",
      "보증금         0\n",
      "월세          0\n",
      "전용면적      787\n",
      "해당층       229\n",
      "총층         16\n",
      "방향          0\n",
      "방수         16\n",
      "욕실수        18\n",
      "주차가능여부      0\n",
      "총주차대수     696\n",
      "관리비         0\n",
      "중개사무소       0\n",
      "제공플랫폼       0\n",
      "게재일         0\n",
      "허위매물여부      0\n",
      "dtype: int64\n",
      "\n",
      "Test set missing values:\n",
      "매물확인방식      0\n",
      "보증금         0\n",
      "월세          0\n",
      "전용면적      184\n",
      "해당층        50\n",
      "총층          2\n",
      "방향          0\n",
      "방수          2\n",
      "욕실수         2\n",
      "주차가능여부      0\n",
      "총주차대수     175\n",
      "관리비         0\n",
      "중개사무소       0\n",
      "제공플랫폼       0\n",
      "게재일         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import font_manager, rc\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import math\n",
    "\n",
    "# 경고 메시지 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
    "fontprop = font_manager.FontProperties(fname=font_path)\n",
    "rc('font', family=fontprop.get_name())\n",
    "\n",
    "# 1. 데이터 로드\n",
    "train = pd.read_csv('/apps/study_promptengineerings/dacon/real_estate_fraud/train.csv')\n",
    "test = pd.read_csv('/apps/study_promptengineerings/dacon/real_estate_fraud/test.csv')\n",
    "\n",
    "# ID 매핑 저장 및 컬럼 제거\n",
    "id_mapping = pd.Series(test['ID'].values, index=test.index)\n",
    "train = train.drop('ID', axis=1)\n",
    "test = test.drop('ID', axis=1)\n",
    "\n",
    "# 결측치 확인\n",
    "print(\"Train set missing values:\")\n",
    "print(train.isnull().sum())\n",
    "print(\"\\nTest set missing values:\")\n",
    "print(test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "허위매물여부\n",
       "0    2154\n",
       "1     298\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['허위매물여부'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set missing values:\n",
      "매물확인방식    0\n",
      "보증금       0\n",
      "월세        0\n",
      "전용면적      0\n",
      "해당층       0\n",
      "총층        0\n",
      "방향        0\n",
      "방수        0\n",
      "욕실수       0\n",
      "주차가능여부    0\n",
      "총주차대수     0\n",
      "관리비       0\n",
      "중개사무소     0\n",
      "제공플랫폼     0\n",
      "게재일       0\n",
      "허위매물여부    0\n",
      "dtype: int64\n",
      "\n",
      "Test set missing values:\n",
      "매물확인방식    0\n",
      "보증금       0\n",
      "월세        0\n",
      "전용면적      0\n",
      "해당층       0\n",
      "총층        0\n",
      "방향        0\n",
      "방수        0\n",
      "욕실수       0\n",
      "주차가능여부    0\n",
      "총주차대수     0\n",
      "관리비       0\n",
      "중개사무소     0\n",
      "제공플랫폼     0\n",
      "게재일       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. 결측치 처리\n",
    "# 2.1 총층 처리\n",
    "train['총층'] = train['총층'].fillna(train['총층'].median())\n",
    "test['총층'] = test['총층'].fillna(test['총층'].median())\n",
    "\n",
    "# 2.2 욕실수 처리\n",
    "train['욕실수'] = train['욕실수'].fillna(train.groupby('방수')['욕실수'].transform('median'))\n",
    "test['욕실수'] = test['욕실수'].fillna(test.groupby('방수')['욕실수'].transform('median'))\n",
    "train['욕실수'] = train['욕실수'].fillna(train['욕실수'].median())\n",
    "test['욕실수'] = test['욕실수'].fillna(test['욕실수'].median())\n",
    "\n",
    "# 2.3 해당층 처리\n",
    "train['해당층'] = train['해당층'].fillna(train['해당층'].median())\n",
    "test['해당층'] = test['해당층'].fillna(test['해당층'].median())\n",
    "\n",
    "# 2.4 전용면적 처리\n",
    "train['전용면적'] = train['전용면적'].fillna(train.groupby(['방수', '욕실수'])['전용면적'].transform('median'))\n",
    "test['전용면적'] = test['전용면적'].fillna(test.groupby(['방수', '욕실수'])['전용면적'].transform('median'))\n",
    "train['전용면적'] = train['전용면적'].fillna(train['전용면적'].median())\n",
    "test['전용면적'] = test['전용면적'].fillna(test['전용면적'].median())\n",
    "\n",
    "# 2.5 총주차대수 처리\n",
    "train.loc[train['주차가능여부'] == '불가능', '총주차대수'] = train.loc[train['주차가능여부'] == '불가능', '총주차대수'].fillna(0)\n",
    "test.loc[test['주차가능여부'] == '불가능', '총주차대수'] = test.loc[test['주차가능여부'] == '불가능', '총주차대수'].fillna(0)\n",
    "\n",
    "train.loc[train['주차가능여부'] == '가능', '총주차대수'] = train.loc[train['주차가능여부'] == '가능', '총주차대수'].fillna(\n",
    "    train.loc[train['주차가능여부'] == '가능', '총주차대수'].median())\n",
    "test.loc[test['주차가능여부'] == '가능', '총주차대수'] = test.loc[test['주차가능여부'] == '가능', '총주차대수'].fillna(\n",
    "    test.loc[test['주차가능여부'] == '가능', '총주차대수'].median())\n",
    "\n",
    "# 2.6 방수 처리\n",
    "# 중개사무소별 평균값으로 방수 결측치 대체\n",
    "train['방수'] = train['방수'].fillna(train.groupby('중개사무소')['방수'].transform('mean'))\n",
    "test['방수'] = test['방수'].fillna(test.groupby('중개사무소')['방수'].transform('mean'))\n",
    "\n",
    "# 남아있는 결측치는 전체 평균값으로 대체\n",
    "train['방수'] = train['방수'].fillna(train['방수'].mean())\n",
    "test['방수'] = test['방수'].fillna(test['방수'].mean())\n",
    "\n",
    "\n",
    "# 결측치 확인\n",
    "print(\"Train set missing values:\")\n",
    "print(train.isnull().sum())\n",
    "print(\"\\nTest set missing values:\")\n",
    "print(test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     매물확인방식          보증금      월세   전용면적  해당층    총층   방향   방수  욕실수 주차가능여부  \\\n",
      "0      현장확인  402500000.0  470000  23.14  4.0  15.0   서향  1.0  1.0     가능   \n",
      "1      현장확인  170500000.0  200000  29.98  3.0   4.0  남동향  2.0  1.0    불가능   \n",
      "2      전화확인  114000000.0  380000  23.14  2.0   3.0   동향  1.0  1.0    불가능   \n",
      "3      현장확인  163500000.0   30000  36.30  3.0   9.0  남동향  2.0  1.0     가능   \n",
      "4      현장확인  346000000.0  530000  29.98  3.0   3.0   동향  2.0  1.0    불가능   \n",
      "...     ...          ...     ...    ...  ...   ...  ...  ...  ...    ...   \n",
      "2447   서류확인  159000000.0  550000  48.95  3.0   3.0   남향  2.0  1.0    불가능   \n",
      "2448   서류확인  158500000.0  750000  23.14  2.0   4.0   남향  1.0  1.0    불가능   \n",
      "2449   전화확인  329000000.0  610000  17.50  8.0  20.0  남서향  1.0  1.0     가능   \n",
      "2450   현장확인   31000000.0  400000  22.87  8.0   9.0  남동향  2.0  1.0     가능   \n",
      "2451   전화확인  126000000.0  340000  29.89  4.0   6.0   북향  2.0  1.0    불가능   \n",
      "\n",
      "      총주차대수  관리비       중개사무소 제공플랫폼  게재일  허위매물여부  \n",
      "0      40.0   96  t93Nt6I2I0  B플랫폼   75       0  \n",
      "1       0.0    0  q39iV5J4E6  D플랫폼   86       0  \n",
      "2       0.0    0  b03oE4G3F6  A플랫폼   82       0  \n",
      "3      13.0   10  G52Iz8V2B9  A플랫폼   82       0  \n",
      "4       0.0    0  N45gM0M7R0  B플랫폼   60       1  \n",
      "...     ...  ...         ...   ...  ...     ...  \n",
      "2447    0.0    0  d22DX4Y4P8  B플랫폼   81       0  \n",
      "2448    0.0    2  g99sy3I3R8  A플랫폼   75       0  \n",
      "2449   29.0   10  G52Iz8V2B9  B플랫폼   54       0  \n",
      "2450    8.0    8  m69GM9O9B3  B플랫폼   66       0  \n",
      "2451    8.0    7  w94Qb4G0K5  B플랫폼   47       0  \n",
      "\n",
      "[2452 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1️⃣ 게재일을 날짜 형식으로 변환 (NaT 발생 시 자동 처리)\n",
    "train[\"게재일\"] = pd.to_datetime(train[\"게재일\"], errors=\"coerce\")\n",
    "test[\"게재일\"] = pd.to_datetime(test[\"게재일\"], errors=\"coerce\")\n",
    "# 2️⃣ 기준 날짜 설정 (최소 날짜)\n",
    "min_date_train = train[\"게재일\"].min()\n",
    "min_date_test = train[\"게재일\"].min()\n",
    "# 3️⃣ 최소 날짜 기준으로 주차 계산 (음수 방지)\n",
    "train[\"게재일_변환\"] = ((train[\"게재일\"] - min_date_train).dt.days // 7).clip(lower=0)\n",
    "test[\"게재일_변환\"] = ((test[\"게재일\"] - min_date_test).dt.days // 7).clip(lower=0)\n",
    "\n",
    "\n",
    "# 4️⃣ 게재일을 변환된 값으로 대체하고, 게재일_변환 열 삭제\n",
    "train[\"게재일\"] = train[\"게재일_변환\"]  # 기존 게재일을 변환된 값으로 대체\n",
    "train.drop(columns=[\"게재일_변환\"], inplace=True)  # 게재일_변환 열 삭제\n",
    "test[\"게재일\"] = test[\"게재일_변환\"]  # 기존 게재일을 변환된 값으로 대체\n",
    "test.drop(columns=[\"게재일_변환\"], inplace=True)  # 게재일_변환 열 삭제\n",
    "\n",
    "# 결과 확인\n",
    "print(train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 피처 인코딩\n",
    "# 3.1 레이블 인코딩, 순서나 크기\n",
    "label_cols = ['방수', '방향', '욕실수']\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    combined_data = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
    "    le.fit(combined_data)\n",
    "    train[col] = le.transform(train[col].astype(str))\n",
    "    test[col] = le.transform(test[col].astype(str))\n",
    "    \n",
    "# 3.2 원-핫 인코딩\n",
    "onehot_cols = ['매물확인방식', '중개사무소', '제공플랫폼', '게재일', '주차가능여부', '해당층', '총층', '총주차대수']\n",
    "onehot = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# 모든 값을 문자열로 변환\n",
    "train[onehot_cols] = train[onehot_cols].astype(str)\n",
    "test[onehot_cols] = test[onehot_cols].astype(str)\n",
    "\n",
    "# 원-핫 인코딩 학습 및 변환\n",
    "onehot.fit(pd.concat([train[onehot_cols], test[onehot_cols]]))\n",
    "\n",
    "# 피처 이름 생성\n",
    "feature_names = onehot.get_feature_names_out(onehot_cols)\n",
    "\n",
    "# 인코딩 적용\n",
    "train_encoded = onehot.transform(train[onehot_cols])\n",
    "test_encoded = onehot.transform(test[onehot_cols])\n",
    "\n",
    "# 데이터프레임 결합\n",
    "train = pd.concat([\n",
    "    train.drop(columns=onehot_cols),\n",
    "    pd.DataFrame(train_encoded, index=train.index, columns=feature_names)\n",
    "], axis=1)\n",
    "\n",
    "test = pd.concat([\n",
    "    test.drop(columns=onehot_cols),\n",
    "    pd.DataFrame(test_encoded, index=test.index, columns=feature_names)\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train, label\u001b[38;5;241m=\u001b[39my_train, weight\u001b[38;5;241m=\u001b[39mweights_train)  \u001b[38;5;66;03m# 가중치 추가\u001b[39;00m\n\u001b[1;32m     27\u001b[0m val_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_val, label\u001b[38;5;241m=\u001b[39my_val)\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mparams\u001b[49m,\n\u001b[1;32m     31\u001b[0m     train_data,\n\u001b[1;32m     32\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[val_data],\n\u001b[1;32m     33\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     34\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     35\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m),\n\u001b[1;32m     36\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mlog_evaluation(period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     37\u001b[0m     ]\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m oof_preds[val_idx] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     41\u001b[0m test_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test) \u001b[38;5;241m/\u001b[39m skf\u001b[38;5;241m.\u001b[39mn_splits\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. 데이터 준비\n",
    "X = train.drop('허위매물여부', axis=1)\n",
    "y = train['허위매물여부']\n",
    "\n",
    "class_weights = dict(zip(\n",
    "    np.unique(y),\n",
    "    1 / np.bincount(y) * len(y) / 2\n",
    "))\n",
    "\n",
    "# 샘플 가중치 계산\n",
    "sample_weights = y.map({0: class_weights[0], 1: class_weights[1]})\n",
    "\n",
    "# 교차 검증 설정\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(test))\n",
    "\n",
    "# 모델 학습\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Training fold {fold + 1}/5\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    weights_train = sample_weights.iloc[train_idx]  # 학습 데이터의 샘플 가중치\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train, weight=weights_train)  # 가중치 추가\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict(X_val)\n",
    "    test_preds += model.predict(test) / skf.n_splits\n",
    "\n",
    "# 결과 확인\n",
    "oof_preds_binary = (oof_preds > 0.5).astype(int)\n",
    "f1 = f1_score(y, oof_preds_binary, average='macro')\n",
    "print(f\"\\nOOF F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. 모델 학습 및 예측\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 25,\n",
    "    'learning_rate': 0.05,\n",
    "    'seed': 42,\n",
    "    'metric': 'binary_logloss',\n",
    "    'n_estimators': 1000,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'min_child_samples': 5,\n",
    "    'scale_pos_weight': class_weights[1]/class_weights[0]  # 클래스 불균형 처리\n",
    "} \n",
    "\n",
    "\n",
    "# 교차 검증 설정\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(test))\n",
    "\n",
    "# 모델 학습\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Training fold {fold + 1}/5\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict(X_val)\n",
    "    test_preds += model.predict(test) / skf.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. 모델 평가\n",
    "oof_preds_binary = (oof_preds > 0.5).astype(int)\n",
    "f1 = f1_score(y, oof_preds_binary, average='macro')\n",
    "print(f\"\\nOOF F1 Score: {f1:.4f}\")\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y, oof_preds_binary)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# 7. 제출 파일 생성\n",
    "test_preds_binary = (test_preds > 0.5).astype(int)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': id_mapping,\n",
    "    '허위매물여부': test_preds_binary\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file has been created successfully!\")\n",
    "\n",
    "# 8. 특성 중요도 시각화\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importance()\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(15))\n",
    "plt.title('Top 15 Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
