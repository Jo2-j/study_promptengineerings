{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import font_manager, rc\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import math\n",
    "\n",
    "# 경고 메시지 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 폰트 경로 설정\n",
    "font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
    "fontprop = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "# matplotlib에 폰트 적용\n",
    "rc('font', family=fontprop.get_name())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "trainDF = pd.read_csv('/apps/study_promptengineerings/dacon/real_estate_fraud/train.csv')\n",
    "testDF = pd.read_csv('/apps/study_promptengineerings/dacon/real_estate_fraud/test.csv')\n",
    "\n",
    "# ID와 인덱스 매핑을 저장\n",
    "id_mapping = pd.Series(testDF['ID'].values, index=testDF.index)\n",
    "\n",
    "# ID 컬럼 제거  \n",
    "trainDF = trainDF.drop('ID', axis=1)\n",
    "testDF = testDF.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     매물확인방식          보증금      월세   전용면적  해당층   총층  방향   방수  욕실수 주차가능여부  총주차대수  \\\n",
      "37     현장확인   25000000.0  520000    NaN  6.0  NaN   3  NaN  NaN    불가능    0.0   \n",
      "76     전화확인   81000000.0   70000    NaN  6.0  NaN   2  NaN  NaN    불가능    0.0   \n",
      "88     현장확인  151000000.0   50000    NaN  6.0  NaN   7  NaN  NaN    불가능    0.0   \n",
      "153    현장확인  167000000.0  380000    NaN  6.0  NaN   3  NaN  NaN     가능    1.0   \n",
      "163    현장확인  128000000.0  360000    NaN  2.0  5.0   4  1.0  NaN     가능    1.0   \n",
      "339    서류확인  194000000.0  360000    NaN  6.0  NaN   2  NaN  NaN    불가능    0.0   \n",
      "456    전화확인   65500000.0  100000    NaN  6.0  NaN   5  NaN  NaN     가능    4.0   \n",
      "515    전화확인  189500000.0  500000    NaN  6.0  NaN   5  NaN  NaN    불가능    0.0   \n",
      "546    서류확인  116000000.0  180000    NaN  6.0  NaN   0  NaN  NaN    불가능    0.0   \n",
      "686    현장확인  181500000.0  520000    NaN  6.0  NaN   7  NaN  NaN    불가능    0.0   \n",
      "952    서류확인  350000000.0  700000    NaN  6.0  NaN   2  NaN  NaN    불가능    0.0   \n",
      "1664   서류확인  367500000.0   90000    NaN  6.0  NaN   6  NaN  NaN    불가능    0.0   \n",
      "1901   현장확인   11000000.0  510000  39.66  6.0  3.0   2  2.0  NaN     가능    1.0   \n",
      "1964   현장확인  120500000.0  610000    NaN  6.0  NaN   5  NaN  NaN     가능    1.0   \n",
      "2071   현장확인  402500000.0  310000    NaN  6.0  NaN   7  NaN  NaN    불가능    0.0   \n",
      "2084   현장확인   78500000.0  470000    NaN  6.0  NaN   2  NaN  NaN    불가능    0.0   \n",
      "2086   현장확인  329000000.0  530000    NaN  6.0  NaN   7  NaN  NaN     가능    5.0   \n",
      "2097   서류확인   81500000.0  710000    NaN  6.0  NaN   6  NaN  NaN    불가능    0.0   \n",
      "\n",
      "      관리비  중개사무소  제공플랫폼  게재일  허위매물여부  \n",
      "37      4    207      3  405       0  \n",
      "76      0     60      3  495       0  \n",
      "88      0     67      3  507       0  \n",
      "153     0    163      3  367       0  \n",
      "163     0    216      3  399       0  \n",
      "339     0     67      3  504       0  \n",
      "456     9    213      2  414       0  \n",
      "515     0     67      3  332       0  \n",
      "546     9    225      2  437       0  \n",
      "686     0     67      3  353       0  \n",
      "952     0     60      3  310       1  \n",
      "1664   14     60      3  214       1  \n",
      "1901    6    272      0  239       0  \n",
      "1964    0     67      3  500       0  \n",
      "2071   13     67      3   27       1  \n",
      "2084    0     67      3  431       0  \n",
      "2086    0     30      2  511       0  \n",
      "2097    0     67      3  241       1  \n",
      "매물확인방식    0.000000\n",
      "보증금       0.000000\n",
      "월세        0.000000\n",
      "전용면적      0.693312\n",
      "해당층       0.000000\n",
      "총층        0.652529\n",
      "방향        0.000000\n",
      "방수        0.652529\n",
      "욕실수       0.734095\n",
      "주차가능여부    0.000000\n",
      "총주차대수     0.000000\n",
      "관리비       0.000000\n",
      "중개사무소     0.000000\n",
      "제공플랫폼     0.000000\n",
      "게재일       0.000000\n",
      "허위매물여부    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 결측치 처리\n",
    "def handle_missing_values(trainDF):\n",
    "    # 1. 총층\n",
    "    def fill_total_floor_with_model(trainDF):\n",
    "        # 학습 데이터와 예측 대상 데이터 분리\n",
    "        total_floor_train_data = trainDF[trainDF['총층'].notnull()]\n",
    "        total_floor_apredict_data = trainDF[trainDF['총층'].isnull()]\n",
    "\n",
    "        # 입력 변수와 타겟 변수 설정\n",
    "        features = ['총주차대수']  # 추가적인 관련 변수 포함\n",
    "        target = '총층'\n",
    "\n",
    "        # 학습 데이터 준비\n",
    "        X = total_floor_train_data[features]\n",
    "        y = total_floor_train_data[target]\n",
    "\n",
    "        # 결측치 데이터 준비\n",
    "        X_predict = total_floor_apredict_data[features]\n",
    "\n",
    "        # 모델 학습\n",
    "        model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "        model.fit(X, y)\n",
    "\n",
    "        # 예측\n",
    "        total_floor_apredict_data['총층'] = model.predict(X_predict)\n",
    "\n",
    "        # 예측값 반영\n",
    "        trainDF.loc[trainDF['총층'].isnull(), '총층'] = total_floor_apredict_data['총층']\n",
    "        return trainDF\n",
    "\n",
    "    # 2. 욕실수\n",
    "    def fill_bathroom_mode(row):\n",
    "        if pd.isnull(row['욕실수']):\n",
    "            mode_value = df[df['방수'] == row['방수']]['욕실수'].mode()\n",
    "            if len(mode_value) > 0:  # 최빈값이 존재하는 경우\n",
    "                return mode_value[0]\n",
    "            else:\n",
    "                return row['욕실수']  # 최빈값이 없으면 그대로 둠\n",
    "        return row['욕실수']\n",
    "\n",
    "    # 3. 해당층 - 총층 중간값(소숫점 올림)\n",
    "    median_total_floor = trainDF['총층'].median()\n",
    "    rounded_median = math.ceil(median_total_floor)\n",
    "    trainDF['해당층'] = trainDF['해당층'].fillna(rounded_median)\n",
    "\n",
    "    # 4. 전용면적 - 방수, 욕실수 모두 같은 값의 평균값으로 채우기\n",
    "    trainDF['전용면적'] = trainDF['전용면적'].fillna(\n",
    "        trainDF.groupby(['방수', '욕실수'])['전용면적'].transform('mean')\n",
    "    )\n",
    "\n",
    "    # 5.1 총주차대수 - 주차불가능인 경우 0으로 채우기\n",
    "    trainDF.loc[trainDF['총주차대수'].isnull() & (trainDF['주차가능여부'] == '불가능'), '총주차대수'] = 0\n",
    "\n",
    "    # 5.2 총주차대수 - 주차가능인 경우 처리\n",
    "    condition = trainDF['총주차대수'].isnull() & (trainDF['주차가능여부'] == '가능')\n",
    "    trainDF['층수_대비_주차대수'] = trainDF.apply(\n",
    "        lambda row: row['총주차대수'] / row['총층'] if pd.notnull(row['총주차대수']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    mean_parking_per_floor = trainDF['층수_대비_주차대수'].mean()\n",
    "    trainDF.loc[condition, '총주차대수'] = trainDF.loc[condition, '총층'] * mean_parking_per_floor\n",
    "    trainDF = trainDF.drop(columns=['층수_대비_주차대수'])\n",
    "\n",
    "    return trainDF\n",
    "\n",
    "# 결측치 처리 적용\n",
    "trainDF = handle_missing_values(trainDF)\n",
    "\n",
    "missing_rows = trainDF[trainDF.isnull().any(axis=1)]\n",
    "print(missing_rows)\n",
    "\n",
    "missing_ratio = trainDF.isnull().sum() / len(trainDF) * 100\n",
    "print(missing_ratio)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩\n",
    "label_encode_cols = ['중개사무소', '게재일', '제공플랫폼', '방향']\n",
    "for col in label_encode_cols:\n",
    "    le = LabelEncoder()\n",
    "    combined_data = pd.concat([trainDF[col], testDF[col]], axis=0).astype(str)\n",
    "    le.fit(combined_data)\n",
    "    trainDF[col] = le.transform(trainDF[col].astype(str))\n",
    "    testDF[col] = le.transform(testDF[col].astype(str))\n",
    "\n",
    "# 원-핫 인코딩\n",
    "one_hot_cols = ['매물확인방식', '주차가능여부']\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "train_encoded = one_hot_encoder.fit_transform(trainDF[one_hot_cols])\n",
    "test_encoded = one_hot_encoder.transform(testDF[one_hot_cols])\n",
    "\n",
    "# 원-핫 인코딩된 열 이름 생성\n",
    "encoded_feature_names = []\n",
    "for col in one_hot_cols:\n",
    "    unique_values = trainDF[col].unique()\n",
    "    encoded_feature_names.extend([f\"{col}_{val}\" for val in unique_values])\n",
    "\n",
    "train = pd.concat([trainDF.drop(columns=one_hot_cols), \n",
    "                  pd.DataFrame(train_encoded, index=trainDF.index, columns=encoded_feature_names)], axis=1)\n",
    "test = pd.concat([testDF.drop(columns=one_hot_cols), \n",
    "                 pd.DataFrame(test_encoded, index=testDF.index, columns=encoded_feature_names)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# SMOTE로 데이터 증강\u001b[39;00m\n\u001b[1;32m      6\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m X_sm, y_sm \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# F1 평가 지표 정의\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mf1_metric\u001b[39m(y_pred, data):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    104\u001b[0m check_classification_targets(y)\n\u001b[1;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m--> 106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/imblearn/base.py:161\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    159\u001b[0m     accept_sparse \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 161\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "X = train.drop(columns=['허위매물여부'])\n",
    "y = train['허위매물여부']\n",
    "\n",
    "# SMOTE로 데이터 증강\n",
    "smote = SMOTE(random_state=42)\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "# F1 평가 지표 정의\n",
    "def f1_metric(y_pred, data):\n",
    "    y_true = data.get_label()\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    return 'f1', f1, True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LightGBM 파라미터 설정\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'class_weight': 'balanced',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# 교차 검증 설정\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(X_sm))\n",
    "test_preds = np.zeros(len(test))\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_sm, y_sm)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_train, X_val = X_sm.iloc[train_idx], X_sm.iloc[val_idx]\n",
    "    y_train, y_val = y_sm.iloc[train_idx], y_sm.iloc[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        valid_sets=[val_data],\n",
    "        feval=f1_metric,\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50),\n",
    "            lgb.log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict(X_val)\n",
    "    test_preds += model.predict(test) / skf.n_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 결과 평가\n",
    "oof_preds_binary = (oof_preds > 0.5).astype(int)\n",
    "print(\"OOF F1 Score:\", f1_score(y_sm, oof_preds_binary, average='macro'))\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_sm, oof_preds_binary)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# 제출 파일 생성\n",
    "test_preds_binary = (test_preds > 0.5).astype(int)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': id_mapping[test.index],  # 처리된 데이터의 인덱스에 해당하는 ID 매핑\n",
    "    '허위매물여부': test_preds_binary\n",
    "})\n",
    "submission.to_csv('submission_2.csv', index=False)\n",
    "print(\"Submission file saved to 'submission_2.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
